{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jInjqS-SboYe"
      },
      "source": [
        "# Extracting Prosodic Features and Visualizing Features\n",
        "\n",
        "**Overview**\n",
        "\n",
        "This notebook has 3 main parts:\n",
        "\n",
        "1. Loading the dataset (still to be determined)\n",
        "2. Extracting features\n",
        "3. Training neural network or other machine learning models\n",
        "4. Testing and performance analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tXQFmY0reIOz",
        "outputId": "2c796698-390c-4771-abd7-31cca9f84028"
      },
      "outputs": [],
      "source": [
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "\n",
        "import scipy.signal as signal\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuNM-s0TcX_M"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54rsNwRQbm5_",
        "outputId": "cdf0eec0-b9e9-4f03-9d20-d0ce89a3842f"
      },
      "outputs": [],
      "source": [
        "#  load dataset\n",
        "\n",
        "'''\n",
        "Example audio paths from weekly assignment 6 used for testing\n",
        "'''\n",
        "\n",
        "data = pd.read_csv(\"N_1000_filtered_train_data.csv\")\n",
        "\n",
        "data = data.dropna()\n",
        "data.drop(columns=['potential_question'], inplace=True)\n",
        "data.drop(columns=['potential_statement'], inplace=True)\n",
        "\n",
        "data = data[data['label'] != 'unknown']\n",
        "\n",
        "print(\"Total rows after filtering: \", data.shape[0])\n",
        "\n",
        "yn = data[data['label'] == 'yn']\n",
        "print(\"Number of clips labeled 'yn': \", yn.shape[0])\n",
        "\n",
        "wh = data[data['label'] == 'wh']\n",
        "print(\"Number of clips labeled 'wh': \", wh.shape[0])\n",
        "\n",
        "imp = data[data['label'] == 'imp']\n",
        "print(\"Number of clips labeled 'imp': \", imp.shape[0])\n",
        "\n",
        "nq = data[data['label'] == 'nq']\n",
        "print(\"Number of clips labeled 'nq': \", nq.shape[0])\n",
        "\n",
        "filtered_data = pd.concat([yn, wh, imp, nq], ignore_index=True)\n",
        "\n",
        "filtered_data = data\n",
        "print(filtered_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl-8QlQyfyhi"
      },
      "source": [
        "# Extract Features \n",
        "\n",
        "**Skip below to load existing features**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKDprXSMf48_"
      },
      "outputs": [],
      "source": [
        "# Example function to extract features\n",
        "\n",
        "def extract_audio_features(audio_path, sr=None):\n",
        "\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "    \n",
        "    # low-pass filter\n",
        "    cutoff_freq = 512  # Cutoff frequency in Hz\n",
        "    nyquist = sr / 2   \n",
        "    normal_cutoff = cutoff_freq / nyquist  \n",
        "\n",
        "    \n",
        "    b, a = signal.butter(4, normal_cutoff, btype='low', analog=False)\n",
        "\n",
        "    y = signal.filtfilt(b, a, y)\n",
        "\n",
        "    # Extract pitch (f0)\n",
        "    f0, voiced_flag, voiced_probs = librosa.pyin(y,\n",
        "                                                fmin=librosa.note_to_hz('C2'),\n",
        "                                                fmax=librosa.note_to_hz('C7'))\n",
        "\n",
        "    # get pitch statistics\n",
        "    f0_valid = f0[~np.isnan(f0)]\n",
        "    end_window = min(len(f0_valid), int(0.5 * sr))  # Last 0.5 seconds\n",
        "    f0_end = f0_valid[-end_window:] if len(f0_valid) > 0 else []\n",
        "\n",
        "    # get energy contour\n",
        "    energy = librosa.feature.rms(y=y)[0]\n",
        "\n",
        "    # get speaking rate proxy using zero crossing rate\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
        "\n",
        "    # get MFCC features\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "\n",
        "    features = {\n",
        "        'f0_mean': np.mean(f0_valid) if len(f0_valid) > 0 else 0,\n",
        "        'f0_std': np.std(f0_valid) if len(f0_valid) > 0 else 0,\n",
        "        'f0_end_slope': np.polyfit(np.arange(len(f0_end)), f0_end, 1)[0] if len(f0_end) > 0 else 0,\n",
        "        'energy_mean': np.mean(energy),\n",
        "        'energy_std': np.std(energy),\n",
        "        'zcr_mean': np.mean(zcr),\n",
        "        'mfcc_means': np.mean(mfccs, axis=1).tolist(),\n",
        "        'filepath' : audio_path\n",
        "    }\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_paths = filtered_data['audio_path'].tolist()\n",
        "\n",
        "features = []\n",
        "\n",
        "for audio_path in audio_paths:\n",
        "  features.append(extract_audio_features(audio_path=audio_path))\n",
        "\n",
        "\n",
        "features_df = pd.DataFrame(features)\n",
        "print(features_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljWfZYKIkV0v",
        "outputId": "875e49c6-49f6-41a2-d0a0-8b0705183d8c"
      },
      "outputs": [],
      "source": [
        "# Combine extracted features with labeled audio clips\n",
        "features_df.rename(columns={'filepath': 'audio_path'}, inplace=True)\n",
        "\n",
        "\n",
        "merged_df = pd.merge(filtered_data, features_df, on='audio_path', how='inner')\n",
        "#print(merged_df.head())\n",
        "\n",
        "merged_df.to_csv(\"N_1000_filtered_train_data_with_features.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run from Here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_df = pd.read_csv(\"N_1000_filtered_train_data_with_features.csv\")\n",
        "features_df2 = features_df.drop(columns=['mfcc_means', 'audio_path', 'text', 'word_count', 'label', 'index'])  # Drop the file path column for PCA\n",
        "features_df2 = features_df2[features_df2['f0_mean'] != 0] # Filter out rows where f0_mean is zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(features_df2)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features_df2)  # Standardize before PCA\n",
        "print(features_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)  # Reduce to 2D\n",
        "features_pca = pca.fit_transform(features_scaled)\n",
        "\n",
        "km = KMeans(n_clusters=4, random_state=23)\n",
        "labels = km.fit_predict(features_pca)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(features_pca[:, 0], features_pca[:, 1], cmap='viridis', alpha=0.7)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA Visualization of Clusters')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=2, random_state=43)\n",
        "features_tsne = tsne.fit_transform(features_scaled)\n",
        "\n",
        "labels = km.fit_predict(features_tsne)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(features_tsne[:, 0], features_tsne[:, 1], cmap='viridis', alpha=0.7)\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE Visualization of Clusters')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sti03bFUlQEm"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKn0deLblUjG"
      },
      "source": [
        "Fundamental Frequency (f0) estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "rh4VgA4KlTSu",
        "outputId": "a23dfe6c-eb91-4616-9d2b-9ebe92b37556"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "from scipy import signal\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"N_1000_filtered_train_data_with_features.csv\")\n",
        "\n",
        "# Select an example\n",
        "index = 2305 # I like this one because it asks \"sorry, say again?\" with an upwards intonation\n",
        "row = data[data['index'] == index]\n",
        "\n",
        "# Get audio path and transcription\n",
        "audio_path = row['audio_path'].values[0]\n",
        "text = row['text'].values[0]\n",
        "print(\"Transcription:\", text)\n",
        "\n",
        "# Load audio\n",
        "y, sr = librosa.load(audio_path)\n",
        "\n",
        "# Apply a low-pass Butterworth filter (optional)\n",
        "apply_filter = False\n",
        "if apply_filter:\n",
        "    cutoff_freq = 512  # Hz\n",
        "    nyquist = sr / 2\n",
        "    normal_cutoff = cutoff_freq / nyquist\n",
        "    b, a = signal.butter(4, normal_cutoff, btype='low')\n",
        "    y = signal.filtfilt(b, a, y)\n",
        "\n",
        "# Estimate pitch\n",
        "f0, voiced_flag, voiced_probs = librosa.pyin(\n",
        "    y,\n",
        "    fmin=librosa.note_to_hz('C2'),\n",
        "    fmax=librosa.note_to_hz('C7')\n",
        ")\n",
        "\n",
        "\n",
        "times = librosa.times_like(f0, sr=sr)\n",
        "\n",
        "D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "img = librosa.display.specshow(D, x_axis='time', y_axis='log', sr=sr, ax=ax, cmap='magma')\n",
        "#fig.colorbar(img, ax=ax, format=\"%+2.0f dB\", label='Amplitude (dB)')\n",
        "\n",
        "# Overlay f0 track\n",
        "ax.plot(times, f0, label='Estimated F0 (pYIN)', color='cyan', linewidth=5, )\n",
        "ax.set(title='Pitch as a Prosodic Feature', xlabel='Time (s)', ylabel='Frequency (Hz)')\n",
        "ax.legend(loc='upper right')\n",
        "ax.set_xlabel(\"Time (s)\")\n",
        "ax.set_ylabel(\"Frequency (Hz)\")\n",
        "ax.set_xlim(0, 0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# play the audio\n",
        "ipd.Audio(y, rate=sr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Data\n",
        "labels = ['Yes/No (yn)', 'Wh-question (wh)', 'Imperative (imp)', 'Non-question (nq)']\n",
        "counts = [95, 100, 236, 554]\n",
        "\n",
        "# Set the style\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Barplot\n",
        "colors = sns.color_palette(\"pastel\")  # Soft colors for a clean poster aesthetic\n",
        "sns.barplot(x=labels, y=counts, palette=colors)\n",
        "\n",
        "# Titles and labels\n",
        "plt.title(\"Label Distribution of Annotated Dataset\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Label Type\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "\n",
        "# Add value labels above bars\n",
        "for i, count in enumerate(counts):\n",
        "    plt.text(i, count + 10, str(count), ha='center', va='bottom', fontsize=11)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WI17MlXlzzy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Data\n",
        "labels = ['Yes/No (yn)', 'Wh-question (wh)', 'Imperative (imp)', 'Non-question (nq)']\n",
        "counts = [95, 100, 236, 554]\n",
        "\n",
        "# Set style\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Horizontal barplot\n",
        "colors = sns.color_palette(\"pastel\")\n",
        "sns.barplot(y=labels, x=counts, palette=colors)\n",
        "\n",
        "# Titles and labels\n",
        "plt.title(\"Label Distribution of Annotated Dataset\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Count\", fontsize=12)\n",
        "plt.ylabel(\"Label Type\", fontsize=12)\n",
        "\n",
        "# Add value labels next to bars\n",
        "for i, count in enumerate(counts):\n",
        "    plt.text(count + 10, i, str(count), va='center', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import signal \n",
        "\n",
        "# Load audio\n",
        "# y, sr = librosa.load(\"your_audio_file.wav\", duration=5)\n",
        "\n",
        "\n",
        "\n",
        "title_fontsize = 30\n",
        "\n",
        "\n",
        "f0, _, _ = librosa.pyin(\n",
        "    y, \n",
        "    fmin=librosa.note_to_hz('C2'), \n",
        "    fmax=librosa.note_to_hz('C7')\n",
        ")\n",
        "\n",
        "# Apply a low-pass  filter\n",
        "apply_filter = True\n",
        "if apply_filter:\n",
        "    cutoff_freq = 512  # Hz\n",
        "    nyquist = sr / 2\n",
        "    normal_cutoff = cutoff_freq / nyquist\n",
        "    b, a = signal.butter(4, normal_cutoff, btype='low')\n",
        "    y = signal.filtfilt(b, a, y)\n",
        "\n",
        "energy = librosa.feature.rms(y=y)[0]\n",
        "zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
        "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "\n",
        "# spectrogram\n",
        "n_fft = 4096\n",
        "hop_length = 256\n",
        "S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=128)\n",
        "S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "\n",
        "frames = np.arange(len(energy))\n",
        "t_feature = librosa.frames_to_time(frames, sr=sr)\n",
        "t_f0 = librosa.times_like(f0, sr=sr)\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(6, 1, figsize=(18, 24), sharex=True)\n",
        "fig.suptitle(\"Audio Feature Comparison for Speech Analysis\", fontsize=35, fontweight='bold')\n",
        "\n",
        "# waveform\n",
        "librosa.display.waveshow(y, sr=sr, ax=axs[0], alpha=0.7, color='steelblue')\n",
        "axs[0].set_title(\"Waveform\", fontsize=title_fontsize, fontweight='bold')\n",
        "axs[0].tick_params(labelsize=16)\n",
        "\n",
        "\n",
        "axs[0].text(0.8, 0.8, '\"Sorry, say again?\"', transform=axs[0].transAxes,\n",
        "            fontsize=24, bbox=dict(facecolor='white', alpha=0.8, boxstyle='round'))\n",
        "\n",
        "# vertical word boundary markers (approximate)\n",
        "word_boundaries = [0.05, 0.26, 0.42, 0.55]\n",
        "for tb in word_boundaries:\n",
        "    axs[0].axvline(tb, color='gray', linestyle='--', alpha=0.7)\n",
        "\n",
        "# spectogram\n",
        "img_spec = librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', cmap='magma', ax=axs[1])\n",
        "axs[1].set_title(\"Mel Spectrogram (dB) (Cutoff = 512Hz)\", fontsize=title_fontsize, fontweight='bold')\n",
        "axs[1].tick_params(labelsize=16)\n",
        "axs[1].set_ylim(0, 550)\n",
        "fig.colorbar(img_spec, ax=axs[1], format=\"%+2.0f dB\")\n",
        "\n",
        "# pitch\n",
        "axs[2].plot(t_f0, f0, color='deepskyblue', linewidth=4)\n",
        "axs[2].set_title(\"Pitch Estimation (pYIN F0)\", fontsize=title_fontsize, fontweight='bold')\n",
        "axs[2].tick_params(labelsize=16)\n",
        "\n",
        "# Highlight pitch inflection region at the end\n",
        "inflection_start = 0.48\n",
        "inflection_end = 0.6\n",
        "axs[2].axvspan(inflection_start, inflection_end, color='orange', alpha=0.3, label='Upwards Inflection')\n",
        "axs[2].legend(fontsize=16)\n",
        "\n",
        "# energy\n",
        "axs[3].plot(t_feature, energy, color='darkorange', linewidth=4)\n",
        "axs[3].set_title(\"RMS Energy\", fontsize=title_fontsize, fontweight='bold')\n",
        "axs[3].tick_params(labelsize=16)\n",
        "\n",
        "# zcr\n",
        "axs[4].plot(t_feature, zcr, color='forestgreen', linewidth=4)\n",
        "axs[4].set_title(\"Zero-Crossing Rate (ZCR)\", fontsize=title_fontsize, fontweight='bold')\n",
        "axs[4].tick_params(labelsize=16)\n",
        "\n",
        "# mfccs\n",
        "img_mfcc = librosa.display.specshow(mfccs, x_axis='time', sr=sr, ax=axs[5], cmap='magma')\n",
        "axs[5].set_title(\"MFCCs (Mel-Frequency Cepstral Coefficients)\", fontsize=title_fontsize, fontweight='bold')\n",
        "axs[5].tick_params(labelsize=16)\n",
        "fig.colorbar(img_mfcc, ax=axs[5], format=\"%+2.0f\")\n",
        "\n",
        "# set x-axis limits for all subplots\n",
        "for ax in axs:\n",
        "    ax.set_xlim(0, 0.6)\n",
        "\n",
        "# Final layout\n",
        "plt.tight_layout(pad=4, rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
