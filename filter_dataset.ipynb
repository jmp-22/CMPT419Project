{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Dataset\n",
    "\n",
    "This notebook filters the data down to N=1000 instances, by selecting 420 questions and 580 statements at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script filters a dataset of ATC (Air Traffic Control) communications\n",
    "# based on word count and identifies potential questions and statements.\n",
    "def filter_atc_dataset(csv_path, output_csv_path, min_words=5):\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(f\"Original dataset size: {len(df)} clips\")\n",
    "    \n",
    "    # Add a column for word count\n",
    "    df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "    \n",
    "    # Filter by word count\n",
    "    df_filtered = df[df['word_count'] >= min_words]\n",
    "    print(f\"After word count filtering: {len(df_filtered)} clips\")\n",
    "    \n",
    "    # Identify potential questions (still requires manual review)\n",
    "    question_patterns = [\n",
    "        r'\\?',                    # Question mark\n",
    "        r'\\b(?:what|where|when|why|who|how|which)\\b',  # WH-questions\n",
    "        r'\\b(?:do|does|did|is|are|was|were|have|has|had|can|could|will|would|should|may|might)\\s+(?:\\w+\\s+)+\\?',  # Yes/no questions\n",
    "        r'\\b(?:right|correct|copy|roger)\\?',  # Common ATC confirmation questions\n",
    "        r'say again',             # Common in ATC for clarification\n",
    "        r'request',               # Often indicates a question in ATC context\n",
    "        r'confirm',               # Confirmation requests\n",
    "    ]\n",
    "    \n",
    "    # Create a combined pattern for detecting questions\n",
    "    combined_pattern = '|'.join(question_patterns)\n",
    "    \n",
    "    # Mark potential questions\n",
    "    df_filtered['potential_question'] = df_filtered['text'].apply(\n",
    "        lambda x: bool(re.search(combined_pattern, str(x).lower())) if pd.notna(x) else False\n",
    "    )\n",
    "    \n",
    "    # Mark potential statements \n",
    "    df_filtered['potential_statement'] = ~df_filtered['potential_question']\n",
    "    \n",
    "    # Save filtered dataset\n",
    "    df_filtered.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"Potential questions: {sum(df_filtered['potential_question'])}\")\n",
    "    print(f\"Potential statements: {sum(df_filtered['potential_statement'])}\")\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 11868 clips\n",
      "After word count filtering: 11642 clips\n",
      "Potential questions: 420\n",
      "Potential statements: 11222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/9sdvxc2d6m750h2y43br5xbr0000gn/T/ipykernel_26362/1460232839.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['potential_question'] = df_filtered['text'].apply(\n",
      "/var/folders/58/9sdvxc2d6m750h2y43br5xbr0000gn/T/ipykernel_26362/1460232839.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['potential_statement'] = ~df_filtered['potential_question']\n"
     ]
    }
   ],
   "source": [
    "# Replace with actual paths\n",
    "csv_path = \"train_data.csv\"\n",
    "output_path = \"filtered_train_data.csv\"\n",
    "\n",
    "filtered_df = filter_atc_dataset(\n",
    "    csv_path, \n",
    "    output_path,\n",
    "    min_words=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index                                               text  \\\n",
      "0    10500              austrian five two hotel juliett praha   \n",
      "1    10425                  austrian seven two nine thank you   \n",
      "2      882                            roger standby for climb   \n",
      "3    10309  csa three charlie tango runway three one clear...   \n",
      "4    11616  sky travel one zero one zero confirm ready for...   \n",
      "..     ...                                                ...   \n",
      "995   2852         lufthansa seven five four please say again   \n",
      "996   7195  direct to polom and when ready direct descend ...   \n",
      "997   5284  lot three nine two praha radar contact stand b...   \n",
      "998    464  good evening air malta five three nine radar r...   \n",
      "999   2768  say again air berlin four zero seven berlin fo...   \n",
      "\n",
      "                      audio_path  word_count  potential_question  \\\n",
      "0    audio_files/audio_10500.wav           6               False   \n",
      "1    audio_files/audio_10425.wav           6               False   \n",
      "2      audio_files/audio_882.wav           4               False   \n",
      "3    audio_files/audio_10309.wav          17               False   \n",
      "4    audio_files/audio_11616.wav          19                True   \n",
      "..                           ...         ...                 ...   \n",
      "995   audio_files/audio_2852.wav           7                True   \n",
      "996   audio_files/audio_7195.wav          14                True   \n",
      "997   audio_files/audio_5284.wav          11               False   \n",
      "998    audio_files/audio_464.wav          20               False   \n",
      "999   audio_files/audio_2768.wav          20                True   \n",
      "\n",
      "     potential_statement label  \n",
      "0                   True  None  \n",
      "1                   True  None  \n",
      "2                   True  None  \n",
      "3                   True  None  \n",
      "4                  False  None  \n",
      "..                   ...   ...  \n",
      "995                False  None  \n",
      "996                False  None  \n",
      "997                 True  None  \n",
      "998                 True  None  \n",
      "999                False  None  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('filtered_train_data.csv')\n",
    "\n",
    "questions = df[df['potential_question']]\n",
    "\n",
    "statements = df[df['potential_statement']]\n",
    "\n",
    "\n",
    "# Randomly sample 580 statements (total rows = 1000)\n",
    "statements_sampled = statements.sample(n=580, random_state=23)  # Set random_state for reproducibility\n",
    "\n",
    "# Concatenate back the questions and the sampled statements\n",
    "df_filtered = pd.concat([questions, statements_sampled])\n",
    "\n",
    "# Shuffle the final dataframe (optional)\n",
    "df_filtered = df_filtered.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# add blank label column for now\n",
    "df_filtered['label'] = None\n",
    "\n",
    "\n",
    "print(df_filtered)\n",
    "\n",
    "# Save the final filtered dataset of length 1000\n",
    "df_filtered.to_csv('N_1000_filtered_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
